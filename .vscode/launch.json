{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Accelerate Launch",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/finetune.py",
            "args": [
                "--model_name_or_path=/root/autodl-tmp/Llama-2-7b-chat-hf",
                "--dataset_name=safety_augmentation",
                "--model_family=llama2",
                "--learning_rate=2e-5",
                "--per_device_train_batch_size=4",
                "--gradient_accumulation_steps=1",
                "--output_dir=/root/autodl-tmp/Llama-2-7b-chat-dropout_0.01",
                "--logging_steps=1",
                "--num_train_epochs=10",
                "--gradient_checkpointing",
                "--report_to=none",
                "--torch_dtype=bfloat16",
                // "--bf16=True",
                "--bf16=False",
                // "--bf16_full_eval=True",
                "--bf16_full_eval=False",
                "--save_strategy=no",
                "--sft_type=sft",
                "--use_anchor=True",
                "--anchor_batch_size_per_device=16",
                "--safety_augmentation=True",
                "--use_warmup=False",
                //另加
                "--use_component_level_dropout=True",
                "--component_level_dropout_rate=0.01",
                "--use_skip_anchor_dropout=True"
            ],
            "console": "integratedTerminal"
        }
    ]
}